import json
from typing import Dict, Any, List

def clean_professor_data(professors_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Limpia los datos de profesores eliminando campos redundantes e innecesarios
    """
    
    # Campos esenciales que debemos mantener
    essential_fields = {
        'name',                      # Nombre del profesor
        'research_papers',           # N√∫mero de publicaciones
        'interest_areas',            # √Åreas de inter√©s
        'interest_scores',           # Puntuaciones de inter√©s
        'degree_level',              # Nivel acad√©mico (PhD, Master, Bachelor)
        'normalized_specialization', # Especializaci√≥n normalizada
        'normalized_university'      # Universidad normalizada
    }
    
    # Campos opcionales √∫tiles (mantener si se quiere informaci√≥n adicional)
    optional_fields = {
        'url_image',                 # URL de imagen del profesor
        'original_degree',           # Grado acad√©mico original (referencia)
        'original_university',       # Universidad original (referencia)
        'specialization'             # Especializaci√≥n sin normalizar
    }
    
    # Campos a eliminar (redundantes o innecesarios)
    fields_to_remove = {
        'degree',                    # Redundante con original_degree
        'university',                # Redundante con original_university
        'scraped_info',              # Informaci√≥n muy detallada innecesaria
        'scraped_name'               # Redundante con name
    }
    
    cleaned_data = []
    
    for professor in professors_data:
        # Crear nuevo diccionario solo con campos necesarios
        cleaned_professor = {}
        
        # Agregar campos esenciales
        for field in essential_fields:
            if field in professor:
                cleaned_professor[field] = professor[field]
        
        # Agregar campos opcionales √∫tiles
        for field in optional_fields:
            if field in professor:
                cleaned_professor[field] = professor[field]
        
        cleaned_data.append(cleaned_professor)
    
    return cleaned_data

def analyze_size_reduction(original_data: List[Dict], cleaned_data: List[Dict]) -> None:
    """
    Analiza la reducci√≥n de tama√±o despu√©s de la limpieza
    """
    def calculate_size(data):
        return len(json.dumps(data, ensure_ascii=False))
    
    original_size = calculate_size(original_data)
    cleaned_size = calculate_size(cleaned_data)
    reduction = original_size - cleaned_size
    reduction_percentage = (reduction / original_size) * 100
    
    print(f"üìä AN√ÅLISIS DE REDUCCI√ìN DE TAMA√ëO:")
    print(f"Tama√±o original: {original_size:,} bytes")
    print(f"Tama√±o limpio: {cleaned_size:,} bytes")
    print(f"Reducci√≥n: {reduction:,} bytes ({reduction_percentage:.1f}%)")

def show_field_comparison(original_data: List[Dict], cleaned_data: List[Dict]) -> None:
    """
    Muestra comparaci√≥n de campos antes y despu√©s
    """
    original_fields = set(original_data[0].keys()) if original_data else set()
    cleaned_fields = set(cleaned_data[0].keys()) if cleaned_data else set()
    
    removed_fields = original_fields - cleaned_fields
    kept_fields = original_fields.intersection(cleaned_fields)
    
    print(f"\nüìù COMPARACI√ìN DE CAMPOS:")
    print(f"Campos originales: {len(original_fields)}")
    print(f"Campos mantenidos: {len(kept_fields)}")
    print(f"Campos eliminados: {len(removed_fields)}")
    
    print(f"\n‚úÖ CAMPOS MANTENIDOS ({len(kept_fields)}):")
    for field in sorted(kept_fields):
        print(f"  ‚Ä¢ {field}")
    
    print(f"\n‚ùå CAMPOS ELIMINADOS ({len(removed_fields)}):")
    for field in sorted(removed_fields):
        print(f"  ‚Ä¢ {field}")

def main():
    """
    Funci√≥n principal que limpia los datos de profesores
    """
    input_file = 'profesores_completos.json'
    
    try:
        print("üßπ Iniciando limpieza de datos...")
        
        # Cargar datos originales
        with open(input_file, 'r', encoding='utf-8') as f:
            original_data = json.load(f)
        
        print(f"üìö Procesando {len(original_data)} profesores...")
        
        # Limpiar datos
        cleaned_data = clean_professor_data(original_data)
        
        # Mostrar comparaciones
        show_field_comparison(original_data, cleaned_data)
        analyze_size_reduction(original_data, cleaned_data)
        
        # Verificar que no perdimos informaci√≥n esencial
        print(f"\nüîç VERIFICACI√ìN DE DATOS ESENCIALES:")
        sample_prof = cleaned_data[0] if cleaned_data else {}
        essential_check = {
            'name': sample_prof.get('name', 'N/A'),
            'degree_level': sample_prof.get('degree_level', 'N/A'),
            'normalized_specialization': sample_prof.get('normalized_specialization', 'N/A'),
            'normalized_university': sample_prof.get('normalized_university', 'N/A'),
            'research_papers': sample_prof.get('research_papers', 'N/A')
        }
        
        for key, value in essential_check.items():
            print(f"  ‚Ä¢ {key}: {value}")
        
        # Guardar datos limpios
        with open(input_file, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ Datos limpios guardados en: {input_file}")
        print("üéâ Limpieza completada exitosamente!")
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo '{input_file}'")
    except json.JSONDecodeError:
        print("‚ùå Error: El archivo JSON no es v√°lido")
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")

if __name__ == "__main__":
    main() 